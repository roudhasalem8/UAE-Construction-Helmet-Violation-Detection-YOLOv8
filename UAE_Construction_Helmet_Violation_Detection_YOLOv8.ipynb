{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roudhasalem8/UAE-Construction-Helmet-Violation-Detection-YOLOv8/blob/main/UAE_Construction_Helmet_Violation_Detection_YOLOv8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TcUO7V7tiBk",
        "outputId": "9ec96eb9-1763-43ba-95fb-5060f457f01d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready!\n"
          ]
        }
      ],
      "source": [
        "#Install & Import Everything\n",
        "!pip install ultralytics supervision albumentations -q\n",
        "\n",
        "import os, shutil, zipfile, cv2, torch\n",
        "import supervision as sv\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "from google.colab import drive\n",
        "print(\"Ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Force GPU usage\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "#Mount Drive & Extract Dataset\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/Hard Hat Workers.v3-v3.yolov8.zip\"\n",
        "\n",
        "shutil.copy(zip_path, \"/content/dataset.zip\")\n",
        "\n",
        "if os.path.exists(\"dataset\"): shutil.rmtree(\"dataset\")\n",
        "with zipfile.ZipFile(\"/content/dataset.zip\", 'r') as f:\n",
        "    f.extractall(\"dataset\")\n",
        "\n",
        "print(\"Dataset extracted!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPwYdpXJti36",
        "outputId": "07e62a7f-f4c6-46b5-d4b0-f4952dbc3225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Dataset extracted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create valid folder\n",
        "os.makedirs(\"dataset/valid/images\", exist_ok=True)\n",
        "os.makedirs(\"dataset/valid/labels\", exist_ok=True)\n",
        "\n",
        "!cp dataset/test/images/* dataset/valid/images/ 2>/dev/null\n",
        "!cp dataset/test/labels/* dataset/valid/labels/ 2>/dev/null\n",
        "\n",
        "yaml_content = \"\"\"\n",
        "path: /content/dataset\n",
        "train: train/images\n",
        "val: valid/images\n",
        "test: test/images\n",
        "nc: 3\n",
        "names:\n",
        "  0: head     # ‚Üê No helmet (DANGER)\n",
        "  1: helmet   # ‚Üê Has helmet (SAFE)\n",
        "  2: person\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/dataset/data.yaml\", \"w\") as f:\n",
        "    f.write(yaml_content.strip() + \"\\n\")\n",
        "\n",
        "print(\"data.yaml fixed correctly!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV76fw_Utkhi",
        "outputId": "93697814-5874-4011-d97c-8626467a5a9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.yaml fixed correctly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4: Check GPU\n",
        "print(\"GPU:\", torch.cuda.is_available())\n",
        "print(\"Name:\", torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "id": "uraYh3CMtmgi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "838df74d-557a-4abb-99db-ab3b2c68e77e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: True\n",
            "Name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 5: TRAIN THE MODEL\n",
        "model = YOLO(\"yolov8m.pt\")\n",
        "\n",
        "model.train(\n",
        "    data=\"/content/dataset/data.yaml\",\n",
        "    epochs=30,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    device=0,\n",
        "    name=\"UAE_Helmet_Detection\",\n",
        "    project=\"/content/runs\",\n",
        "    patience=0,         # no early stopping\n",
        "    optimizer=\"AdamW\",\n",
        "    lr0=0.001,\n",
        "    augment=True,\n",
        "    conf=0.25,\n",
        "    iou=0.6,\n",
        "    plots=True,\n",
        "    save=True,\n",
        "    exist_ok=True,\n",
        "    resume=False        # start fresh for speed\n",
        ")\n",
        "\n",
        "print(\"Training Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWte3wYNtoOV",
        "outputId": "d7b96e20-b46f-4be6-eb6c-ca0c58c06b79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.232 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=0.25, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.6, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=UAE_Helmet_Detection, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=0, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/UAE_Helmet_Detection, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3777433  ultralytics.nn.modules.head.Detect           [3, [192, 384, 576]]          \n",
            "Model summary: 169 layers, 25,858,057 parameters, 25,858,041 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1627.1¬±428.7 MB/s, size: 49.6 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/train/labels... 15807 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 15807/15807 2.3Kit/s 6.9s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 895.3¬±348.0 MB/s, size: 51.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/valid/labels... 1766 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1766/1766 1.0Kit/s 1.7s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset/valid/labels.cache\n",
            "Plotting labels to /content/runs/UAE_Helmet_Detection/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/UAE_Helmet_Detection\u001b[0m\n",
            "Starting training for 8 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K        1/8      6.36G      1.491      1.115      1.396        119        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 988/988 1.8it/s 8:55\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 56/56 2.2it/s 25.5s\n",
            "                   all       1766       6666      0.914      0.859      0.919       0.59\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K        2/8      6.52G      1.447      1.007      1.369         85        640: 36% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 353/988 1.8it/s 3:10<6:00"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Best Model\n",
        "best_model = YOLO(\"/content/runs/UAE_Helmet_Detection/weights/best.pt\")\n",
        "print(\"Best model loaded!\")"
      ],
      "metadata": {
        "id": "ngkVdA9atqXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test on Your Image\n",
        "!wget -q \"https://i.imgur.com/8k5iH9p.jpg\" -O test.jpg\n",
        "\n",
        "# Run inference\n",
        "results = best_model(\"test.jpg\", conf=0.4)[0]\n",
        "detections = sv.Detections.from_ultralytics(results)\n",
        "\n",
        "# Show normal detection\n",
        "sv.plot_image(results.plot(), (14, 10))"
      ],
      "metadata": {
        "id": "gwbfKRqHtrf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SMART \"NO HELMET\" ALERT\n",
        "img = results.orig_img.copy()\n",
        "\n",
        "# Separate heads and helmets\n",
        "head_boxes = [box for i, box in enumerate(detections.xyxy) if detections.class_id[i] == 0]\n",
        "helmet_boxes = [box for i, box in enumerate(detections.xyxy) if detections.class_id[i] == 1]\n",
        "\n",
        "no_helmet = []\n",
        "\n",
        "for h_box in head_boxes:\n",
        "    hx1, hy1, hx2, hy2 = map(int, h_box)\n",
        "    head_cx = (hx1 + hx2) // 2\n",
        "    head_cy = (hy1 + hy2) // 2\n",
        "\n",
        "    has_helmet = False\n",
        "    for helm_box in helmet_boxes:\n",
        "        hx1h, hy1h, hx2h, hy2h = map(int, helm_box)\n",
        "        if hx1h < head_cx < hx2h and hy1h < head_cy < hy2h + 60:\n",
        "            has_helmet = True\n",
        "            break\n",
        "\n",
        "    if not has_helmet:\n",
        "        no_helmet.append(h_box)\n",
        "\n",
        "# Draw alerts\n",
        "alert_img = img.copy()\n",
        "for box in no_helmet:\n",
        "    x1, y1, x2, y2 = map(int, box)\n",
        "    cv2.rectangle(alert_img, (x1, y1), (x2, y2), (0, 0, 255), 5)\n",
        "    cv2.putText(alert_img, \"NO HELMET!\", (x1, y1-20),\n",
        "                cv2.FONT_HERSHEY_DUPLEX, 1.2, (0, 0, 255), 4)\n",
        "\n",
        "print(f\"ALERT: {len(no_helmet)} worker(s) WITHOUT helmet\")\n",
        "sv.plot_image(alert_img, (16, 10))"
      ],
      "metadata": {
        "id": "LRZSN-W5ts46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export + Download Everything\n",
        "best_model.export(format=\"onnx\", imgsz=640, simplify=True)\n",
        "\n",
        "!zip -r UAE_Helmet_Final_Result.zip \\\n",
        "  /content/runs/UAE_Helmet_Detection/weights/best.pt \\\n",
        "  /content/runs/UAE_Helmet_Detection/weights/best.onnx \\\n",
        "  test.jpg\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"UAE_Helmet_Final_Result.zip\")"
      ],
      "metadata": {
        "id": "TMgzv9rCtu0j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}